{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/spark-nlp-transformers/blob/main/HuggingFace_in_Spark_NLP_DeBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lshuevA3Qv-N"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DeBERTa.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zva6MvJyLeWi"
      },
      "source": [
        "## Import DeBERTa models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n",
        "\n",
        "Let's keep in mind a few things before we start ðŸ˜Š \n",
        "\n",
        "- This feature is only available in `Spark NLP 3.4.2` and above. So please make sure you have upgraded to the latest Spark NLP release\n",
        "- You can import models for DeBERTa from HuggingFace but they have to be compatible with `TensorFlow` and they have to be in `Fill Mask` category. Meaning, you cannot use DeBERTa models trained/fine-tuned on a specific task such as token/sequence classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzxB-Nq6cxOA"
      },
      "source": [
        "## Export and Save HuggingFace model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNQkhyMHMgkE"
      },
      "source": [
        "- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n",
        "- We lock TensorFlow on `2.8.0` version and Transformers on `4.18.0`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully.\n",
        "- DebertaV2Tokenizer requires the `SentencePiece` library, so we install that as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHXgqiWpMfCY"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.17.0 tensorflow==2.8.0 sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3AM6bj4P3NS"
      },
      "source": [
        "- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n",
        "- We'll use [microsoft/deberta-v3-xsmall](https://huggingface.co/microsoft/deberta-v3-xsmall) model from HuggingFace as an example\n",
        "- In addition to `TFDebertaV2Model` we also need to save the `DebertaV2Tokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP.\n",
        "- Since `microsoft/deberta-v3-xsmall` model is PyTorch we will use `from_pt=True` param to convert it to TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaiirlSKNhVD"
      },
      "outputs": [],
      "source": [
        "from transformers import DebertaV2Tokenizer, TFDebertaV2Model\n",
        "import tensorflow as tf\n",
        "\n",
        "MODEL_NAME = 'microsoft/deberta-v3-xsmall'\n",
        "\n",
        "DebertaV2Tokenizer.from_pretrained(MODEL_NAME, return_tensors=\"pt\").save_pretrained(\"./{}_tokenizer\".format(MODEL_NAME))\n",
        "\n",
        "# just in case if there is no TF/Keras file provided in the model\n",
        "# we can just use `from_pt` and convert PyTorch to TensorFlow\n",
        "try:\n",
        "  print('try downloading TF weights')\n",
        "  model = TFDebertaV2Model.from_pretrained(MODEL_NAME)\n",
        "except:\n",
        "  print('try downloading PyTorch weights')\n",
        "  model = TFDebertaV2Model.from_pretrained(MODEL_NAME, from_pt=True)\n",
        "\n",
        "model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlgyZuJfS5IB"
      },
      "source": [
        "Let's have a look inside these two directories and see what we are dealing with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2XCole7TTef"
      },
      "outputs": [],
      "source": [
        "!ls -l {MODEL_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0DOGz8VUR-r"
      },
      "outputs": [],
      "source": [
        "!ls -l {MODEL_NAME}/saved_model/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcm2UpNxUUQN"
      },
      "outputs": [],
      "source": [
        "!ls -l {MODEL_NAME}_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZegMvuGTmHt"
      },
      "source": [
        "- as you can see, we need the SavedModel from `saved_model/1/` path\n",
        "- we also be needing `spiece.model` file from the tokenizer\n",
        "- all we need is to copy `spiece.model` file into `saved_model/1/assets` which Spark NLP will look for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez6MT-RTT7ss"
      },
      "outputs": [],
      "source": [
        "# let's copy spiece.model file to saved_model/1/assets\n",
        "!cp {MODEL_NAME}_tokenizer/spm.model {MODEL_NAME}/saved_model/1/assets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlJKd2tIU0PD"
      },
      "source": [
        "## Import and Save DeBERTa in Spark NLP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0FXoxHJc5CU"
      },
      "source": [
        "- Let's install and setup Spark NLP in Google Colab\n",
        "- This part is pretty easy via our simple script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tpW5nkMc53m"
      },
      "outputs": [],
      "source": [
        "! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_NAgx4hdCGP"
      },
      "source": [
        "Let's start Spark with Spark NLP included via our simple `start()` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGXPlbLdBvbm"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "# let's start Spark with Spark NLP\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABTu9MrdVafM"
      },
      "source": [
        "- Let's use `loadSavedModel` functon in `DeBertaEmbeddings` which allows us to load TensorFlow model in SavedModel format\n",
        "- Most params can be set later when you are loading this model in `DeBertaEmbeddings` in runtime, so don't worry what you are setting them now\n",
        "- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n",
        "- `setStorageRef` is very important. When you are training a task like NER or any Text Classification, we use this reference to bound the trained model to this specific embeddings so you won't load a different embeddings by mistake and see terrible results ðŸ˜Š\n",
        "- It's up to you what you put in `setStorageRef` but it cannot be changed later on. We usually use the name of the model to be clear, but you can get creative if you want! \n",
        "- The `dimension` param is is purely cosmetic and won't change anything. It's mostly for you to know later via `.getDimension` what is the dimension of your model. So set this accordingly.\n",
        "- NOTE: `loadSavedModel` only accepts local paths and not distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. That is why we use `write.save` so we can use `.load()` from any file systems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W_almibVRTj"
      },
      "outputs": [],
      "source": [
        "from sparknlp.annotator import *\n",
        "\n",
        "deberta = DeBertaEmbeddings.loadSavedModel(\n",
        "     '{}/saved_model/1'.format(MODEL_NAME),\n",
        "     spark\n",
        " )\\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"embeddings\")\\\n",
        " .setCaseSensitive(False)\\\n",
        " .setDimension(768)\\\n",
        " .setStorageRef('deberta_v3_xsmall') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjGiq4KnXWuy"
      },
      "source": [
        "- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWu5HfbnXAlM"
      },
      "outputs": [],
      "source": [
        "deberta.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2m4JuVDM3D"
      },
      "source": [
        "Let's clean up stuff we don't need anymore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnUXH76ADSkL"
      },
      "outputs": [],
      "source": [
        "!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TSeTRZpXqWO"
      },
      "source": [
        "Awesome ðŸ˜Ž  !\n",
        "\n",
        "This is your DeBERTa model from HuggingFace ðŸ¤— loaded and saved by Spark NLP ðŸš€ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogpxSWxOXj3W"
      },
      "outputs": [],
      "source": [
        "! ls -l {MODEL_NAME}_spark_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbehje7fYTDj"
      },
      "source": [
        "Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny RoBERTa model ðŸ˜Š "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mm3CvkwYRgs"
      },
      "outputs": [],
      "source": [
        "deberta_loaded = DeBertaEmbeddings.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
        "  .setInputCols([\"sentence\",'token'])\\\n",
        "  .setOutputCol(\"embeddings\")\\\n",
        "  .setCaseSensitive(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGRTNISyYlnO"
      },
      "outputs": [],
      "source": [
        "deberta_loaded.getStorageRef()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_he2LDtBYo1h"
      },
      "source": [
        "That's it! You can now go wild and use hundreds of DeBERTa models from HuggingFace ðŸ¤— in Spark NLP ðŸš€ \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HuggingFace in Spark NLP - DeBERTa.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}